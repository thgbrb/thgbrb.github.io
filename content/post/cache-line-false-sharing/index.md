+++
author = "Thiago Borba"
title = "Cachelines e False Sharing"
slug = "cache-line-false-sharing"
date = "2021-07-15"
description = "False sharing √© um problema que ocorre quando threads f√≠sicas paralelas acessam uma mesma cacheline que possui dados pequenos e que sofrem altera√ß√µes constantes. False sharing √© um problema universal em processadores onde as linhas de cache s√£o compartilhadas com mais de uma thread."
tags = [
"Performance",
"Programa√ß√£o Paralela",
]
categories = [
"LowLevel",
]
image = "cacheline.png"
+++

## CPU Cache
Os processadores possuem estrat√©gias de caching para manter as pr√≥ximas instru√ß√µes a serem executadas e blocos
de dados a serem manipulados o mais pr√≥ximo de uma thread, economizando ciclos para buscar dados na mem√≥ria RAM; busca que no contexto de CPU √© extremamente lento.
O cache de CPU √© distribu√≠do em n√≠veis, onde L1 √© um cache muito pequeno exclusivo para um core e compartilhado com as suas threads e o L2 √© um
cache um pouco maior compartilhado por um grupo de core.

### Cacheline
O processador busca dados na mem√≥ria em blocos e n√£o ‚Äòbyte‚Äô a ‚Äòbyte‚Äô. Esses blocos de dados s√£o chamados de cacheline.
Quando o processador l√™ um determinado ponto da mem√≥ria ele busca, a partir desse ponto,
a quantidade de dados equivalentes ao tamanho da cacheline.
Em m√©dia uma linha de cache possui 64 ‚Äòbytes‚Äô, variando de acordo com a arquitetura do processador. Quanto maior o tamanho do cache
maior √© quantidade de linhas, ou seja, menor √© quantidade de leituras na mem√≥ria RAM.

| Processador| Cache L1 | Cache L2 | Cache L3| Lan√ßamento | Pre√ßo|
|---|---|---|---|---|---|
|i7-9750H|32K|256K|12M|2019|~USD 395|
|Xeon E5-2620 |384K|1,5M|15M|2012|~USD 410|

> **Tamanho do cache e cacheline**
> 
> Para verificar o tamanho do cache e cacheline em uma m√°quina com Windows, [utilize o aplicativo Coreinfo da Sysinternal.](https://docs.microsoft.com/en-us/sysinternals/downloads/coreinfo)
> ![Execu√ß√£o do Coreinfo](coreinfo.png)

### Cache coherence protocol
As CPUs modernas na sua maioria possuem mais de uma thread por core, utilizando t√©cnicas de programa√ß√£o paralela. 
Uma das estrat√©gias √© utilizar as micropausas de uma thread f√≠sica (ex.: buscar dados na mem√≥ria RAM) para que outra thread
execute alguma opera√ß√£o.

> Tecnologia propriet√°ria
> 
> Cada fornecedor define a sua tecnologia para maximizar o desempenho de um processador.
> - [Intel Hyper-thread](https://www.intel.com.br/content/www/br/pt/gaming/resources/hyper-threading.html)
> - [AMD Simultaneous Multithreading](https://www.amd.com/)

As threads f√≠sicas compartilham o cache L1 exclusivo do seu core, assim como o cache L2, que √© compartilhado por um grupo de core e outros
n√≠veis de cache possam existir. Por fim, acima dessa estrutura de cache, existe a mem√≥ria RAM.

{{< figure src="800px-Non_Coherent.gif" title="Uso de cache sem coer√™ncia/integridade (fig wikip√©dia)" width="500" >}}

Dado o cen√°rio de paralelismo, a CPU deve implementar estrat√©gias de sincroniza√ß√£o desses dados para evitar o problema demonstrado na imagem acima.
Essa estrat√©gia √© chamada de **Cache coherence protocol**. Esse protocolo √© respons√°vel por manter a coer√™ncia e integridade no cache.

{{< figure src="800px-Coherent.gif" title="Estrat√©gia de coer√™ncia (fig wikip√©dia)" width="500" >}}

### Otimiza√ß√£o de compiladores
Os compiladores modernos al√©m gerarem c√≥digos que utilizam os recursos fornecidos pelas CPUs tamb√©m implementam estrat√©gias e t√©cnicas
de otimiza√ß√£o, com o objetivo de extrair o m√°ximo do hardware. Por√©m, nem sempre os compiladores conseguem gerar o c√≥digo mais perform√°tico 
por uma s√©rie de motivos, que sozinhos s√£o tema de um futuro post.
Dificilmente esses problemas s√£o detectados nos processos de desenvolvimento e/ou qualidade. N√£o √© incomum que eles ocorram somente em 
produ√ß√£o de forma n√£o determin√≠stica.

## False sharing
Em algumas situa√ß√µes o c√≥digo de um programador n√£o consegue ser otimizado pelo compilador, o que introduz problemas
de desempenho ou at√© mesmo falhas. Uma dessas situa√ß√µes √© o **false sharing**. O false sharing ocorre quando o **cache coherence protocol**
entende ser necess√°rio atualizar uma determinada linha de cache, fazendo com que ocorra uma nova leitura do dado na mem√≥ria RAM. 
_Lembrando que leitura de mem√≥ria RAM num contexto de CPU √© uma opera√ß√£o lenta!_ 

Quando threads f√≠sicas fazem **leituras** e **grava√ß√µes** **frequentes** de um **dado** muito **pequeno** que est√£o alinhados na mem√≥ria RAM num cen√°rio de **paralelismo**
essa situa√ß√£o ocorrer√°.

Nos exemplos abaixo temos um c√≥digo cujo objetivo √© para cada posi√ß√£o de um array de inteiros incrementar o valor da refer√™ncia num ‚Äòlooping for‚Äô 1.000.000 de vezes.
> Foi utilizado um laptop com um processador i7-9750H para os testes.

### Cen√°rio A - False sharing
 **17,435** segundos para finalizar o processamento.
```csharp
private readonly int[] sharedArray = new int[4];

public void CenarioA()
{
    var task1 = Task.Run(() => Inc(0));
    var task2 = Task.Run(() => Inc(1));
    var task3 = Task.Run(() => Inc(2));
    var task4 = Task.Run(() => Inc(3));

    Task.WaitAll(task1, task2, task3, task4);
}

private void Inc(int position)
{
    for (var i = 0; i < 1_000_000; i++)
        sharedArray[position]++;
}
```

### Cen√°rio B - Otimiza√ß√£o de c√≥digo
**5,72** segundos para finalizar o processamento.
```csharp
private readonly int[] sharedArray = new int[64];

public void CenarioB()
{
    var task1 = Task.Run(() => Inc(0));
    var task2 = Task.Run(() => Inc(16));
    var task3 = Task.Run(() => Inc(32));
    var task4 = Task.Run(() => Inc(48));

    Task.WaitAll(task1, task2, task3, task4);
}

private void Inc(int position)
{
    for (var i = 0; i < 1_000_000; i++)
        sharedArray[position]++;
}
```

### Benchmark Cen√°rios A e B
No benchmark observamos que o Cen√°rio B executou aproximadamente 3x mais r√°pido que o cen√°rio A.

![Benchmark A x B](benchmark.png)

No Cen√°rioA todas as threads compartilham a mesma cacheline para leitura e grava√ß√£o. Isso faz o cache coherence protocol 
invalidar diversas vezes a cacheline e consequentemente a CPU deve buscar na mem√≥ria RAM o valor atualizado.
J√° no Cen√°rioB utilizamos uma estrat√©gia onde cada thread utiliza uma cacheline diferente! Para fazer isso √© utilizado 
saltos de 16 posi√ß√µes no array de inteiro, ou seja:

|Quantidade de Int32| Tamanho Int32|Tamanho ocupado|
|---|---|---|
|16|4 bytes|16 x 4 bytes = 64 bytes|

Considerando que o processador onde o benchmark √© executado possui uma cacheline de 64 ‚Äòbytes‚Äô, cada thread utilizar√° uma 
cacheline diferente.

## Conclus√£o
Apesar dos compiladores ocultarem parte da complexidade da programa√ß√£o paralela h√° cen√°rios que precisam da interven√ß√£o do programador.
Entender como funciona aloca√ß√£o de mem√≥ria na sua stack de desenvolvimento assim como conhecer o funcionamento de componentes de hardware
s√£o ferramentas essenciais para a escrita de c√≥digos de alto desempenho e otimizados.

> üëâ Dica ‚ò†Ô∏è
> 
> Otimiza√ß√£o prematura do c√≥digo traz complexidade sem agregar valor! Evite :)

> ü§Ø **Informa√ß√£o**
> 
> False sharing √© um problema universal em processadores multithreading que compartilham cache. 
> O exemplo acima funciona em qualquer linguagem :) 